{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f988a2-9a6f-4ed6-a2b6-ebb9366a0200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing checkpoint with 3993 entries\n",
      "3993\n",
      "Loaded data: 4000 rows\n",
      "\n",
      "Processing batch 80/1\n",
      "\n",
      "Progress saved: 4000 Q&A pairs written to vqa_dataset_groq_checkpoint_3.csv\n",
      "Processed 4000/4000 images (100.00%)\n",
      "\n",
      "Progress saved: 4000 Q&A pairs written to vqa_dataset_groq_final_1.csv\n",
      "\n",
      "Final processing complete: 4000/4000 images processed\n",
      "Successfully generated 4000 Q&A pairs\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from random import uniform\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import base64\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Configure multiple API keys\n",
    "API_KEYS = [\n",
    "    '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'\n",
    "]\n",
    "\n",
    "current_api_key_index = 0\n",
    "api_request_count = 0\n",
    "MAX_REQUESTS_PER_KEY = 1450\n",
    "\n",
    "def switch_to_next_api_key():\n",
    "    \"\"\"Switch to the next available API key\"\"\"\n",
    "    global current_api_key_index, api_request_count\n",
    "    current_api_key_index = (current_api_key_index + 1) % len(API_KEYS)\n",
    "    api_request_count = 0\n",
    "    print(f\"\\nSwitching to API key {current_api_key_index + 1}\")\n",
    "    time.sleep(2)  # Brief pause when switching keys\n",
    "\n",
    "# Initialize with first API key\n",
    "client = Groq(api_key=API_KEYS[current_api_key_index])\n",
    "\n",
    "@retry(\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    stop=stop_after_attempt(3),\n",
    "    retry=retry_if_exception_type(Exception)\n",
    ")\n",
    "def generate_qa_groq(image_path, product_info):\n",
    "    \"\"\"Generates a question-answer pair using GROQ Vision API with rate limiting.\"\"\"\n",
    "    global api_request_count\n",
    "    \n",
    "    try:\n",
    "        # Check if we need to switch API keys\n",
    "        if api_request_count >= MAX_REQUESTS_PER_KEY:\n",
    "            if current_api_key_index == len(API_KEYS) - 1:\n",
    "                print(\"\\nAll API keys exhausted. Saving progress...\")\n",
    "                return None, None, True  # Third parameter indicates API exhaustion\n",
    "            switch_to_next_api_key()\n",
    "        \n",
    "        # Add random delay between requests (2-3 seconds)\n",
    "        time.sleep(uniform(2, 3))\n",
    "        \n",
    "        # Encode the image to base64\n",
    "        base64_image = encode_image(image_path)\n",
    "        \n",
    "        prompt = f\"\"\"Analyze this product image carefully. The image resolution is 256x256 pixels.\n",
    "\n",
    "Product Information:\n",
    "{product_info}\n",
    "\n",
    "Task:\n",
    "1. Look at the product and identify:\n",
    "   - The main visible object/product category\n",
    "   - Prominent colors\n",
    "   - Materials or textures\n",
    "   - Basic shape or form\n",
    "   - Notable features or attributes\n",
    "\n",
    "Requirements:\n",
    "1. Generate ONE question that:\n",
    "   - Must be clearly answerable from the image\n",
    "   - Must have a single-word answer only\n",
    "   - Must focus on obvious visual features\n",
    "2. Avoid questions about:\n",
    "   - Small text or details\n",
    "   - Measurements or dimensions\n",
    "   - Subjective qualities\n",
    "   - Brand names unless clearly visible\n",
    "\n",
    "Output Format (STRICT):\n",
    "Question: <single clear question about visible feature>\n",
    "Answer: <single word only>\n",
    "\n",
    "Example Good Outputs:\n",
    "Question: What color is this shirt?\n",
    "Answer: blue\n",
    "\n",
    "Question: What material is this table made of?\n",
    "Answer: wood\"\"\"\n",
    "\n",
    "        # GROQ API call\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "        )\n",
    "        \n",
    "        # Increment request count\n",
    "        api_request_count += 1\n",
    "        \n",
    "        # Parse the response\n",
    "        response_text = chat_completion.choices[0].message.content\n",
    "        question = response_text.split(\"Question:\")[1].split(\"Answer:\")[0].strip()\n",
    "        answer = response_text.split(\"Answer:\")[1].strip()\n",
    "        \n",
    "        return question, answer, False  # False indicates API not exhausted\n",
    "    \n",
    "    except Exception as e:\n",
    "        if \"quota exceeded\" in str(e).lower():\n",
    "            print(f\"\\nQuota exceeded for API key {current_api_key_index + 1}\")\n",
    "            if current_api_key_index == len(API_KEYS) - 1:\n",
    "                print(\"All API keys exhausted. Saving progress...\")\n",
    "                return None, None, True\n",
    "            switch_to_next_api_key()\n",
    "            return None, None, False\n",
    "        else:\n",
    "            print(f\"GROQ Error for {image_path}: {e}\")\n",
    "            return None, None, False\n",
    "\n",
    "# Try to load existing checkpoint\n",
    "try:\n",
    "    last_checkpoint = pd.read_csv(\"vqa_dataset_groq_final_1.csv\")\n",
    "    print(f\"Loaded existing checkpoint with {len(last_checkpoint)} entries\")\n",
    "    paths = last_checkpoint['path'].tolist()\n",
    "    questions = last_checkpoint['generated_question'].tolist()\n",
    "    answers = last_checkpoint['generated_answer'].tolist()\n",
    "    processed_count = len(last_checkpoint)\n",
    "    checkpoint_num = 2\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing checkpoint found. Starting fresh.\")\n",
    "    paths = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    processed_count = 0\n",
    "    checkpoint_num = 0\n",
    "\n",
    "print(processed_count)\n",
    "\n",
    "# Ensure clean_df is properly initialized\n",
    "try:\n",
    "    clean_df = pd.read_csv(\"sampled_metadata_stratified_1.csv\")  # Replace with your actual data file path\n",
    "    print(f\"Loaded data: {len(clean_df)} rows\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found. Please provide the correct path to your data.\")\n",
    "    clean_df = pd.DataFrame()  # Initialize as an empty DataFrame in case of failure\n",
    "\n",
    "total_images = len(clean_df)\n",
    "save_interval = 100  # Save more frequently\n",
    "batch_size = 50\n",
    "\n",
    "def save_progress(paths, questions, answers, is_final=False):\n",
    "    \"\"\"Save current progress to CSV\"\"\"\n",
    "    if len(paths) > 0:\n",
    "        temp_df = pd.DataFrame({\n",
    "            'path': paths,\n",
    "            'generated_question': questions,\n",
    "            'generated_answer': answers\n",
    "        })\n",
    "        \n",
    "        if is_final:\n",
    "            filename = \"vqa_dataset_groq_final_1.csv\"\n",
    "        else:\n",
    "            filename = f\"vqa_dataset_groq_checkpoint_{checkpoint_num}.csv\"\n",
    "        \n",
    "        temp_df.to_csv(filename, index=False)\n",
    "        print(f\"\\nProgress saved: {len(paths)} Q&A pairs written to {filename}\")\n",
    "\n",
    "# Skip already processed images\n",
    "clean_df = clean_df[processed_count:]\n",
    "\n",
    "try:\n",
    "    # Iterate through the DataFrame in batches\n",
    "    for batch_start in range(0, len(clean_df), batch_size):\n",
    "        current_batch = (batch_start + processed_count) // batch_size + 1\n",
    "        total_batches = (len(clean_df) + batch_size - 1) // batch_size\n",
    "        print(f\"\\nProcessing batch {current_batch}/{total_batches}\")\n",
    "        \n",
    "        # Add a pause between batches\n",
    "        if batch_start > 0:\n",
    "            print(\"Pausing between batches...\")\n",
    "            time.sleep(30)  # 30-second pause between batches\n",
    "        \n",
    "        # Get current batch\n",
    "        batch = clean_df[batch_start:batch_start + batch_size]\n",
    "        \n",
    "        for index, row in batch.iterrows():\n",
    "            image_path = os.path.join(\"small\", row['path'])\n",
    "            \n",
    "            # Construct product info\n",
    "            product_info_parts = []\n",
    "            if pd.notna(row['model_name']):\n",
    "                product_info_parts.append(f\"Model: {row['model_name']}\")\n",
    "            if pd.notna(row['color']):\n",
    "                product_info_parts.append(f\"Color: {row['color']}\")\n",
    "            if pd.notna(row['product_type']):\n",
    "                product_info_parts.append(f\"Type: {row['product_type']}\")\n",
    "            if pd.notna(row['material']):\n",
    "                product_info_parts.append(f\"Material: {row['material']}\")\n",
    "            if pd.notna(row['style']):\n",
    "                product_info_parts.append(f\"Style: {row['style']}\")\n",
    "            if pd.notna(row['pattern']):\n",
    "                product_info_parts.append(f\"Pattern: {row['pattern']}\")\n",
    "            if pd.notna(row['item_shape']):\n",
    "                product_info_parts.append(f\"Shape: {row['item_shape']}\")\n",
    "            \n",
    "            product_info = \", \".join(product_info_parts)\n",
    "\n",
    "            question, answer, apis_exhausted = generate_qa_groq(image_path, product_info)\n",
    "\n",
    "            if apis_exhausted:\n",
    "                # Save progress and exit\n",
    "                save_progress(paths, questions, answers, is_final=True)\n",
    "                print(f\"\\nProcessing stopped at {processed_count}/{total_images} images\")\n",
    "                print(f\"Successfully generated {len(paths)} Q&A pairs\")\n",
    "                break\n",
    "            \n",
    "            if question and answer:\n",
    "                paths.append(row['path'])\n",
    "                questions.append(question)\n",
    "                answers.append(answer)\n",
    "\n",
    "                # Save more frequently\n",
    "                if len(paths) % save_interval == 0:\n",
    "                    checkpoint_num += 1\n",
    "                    save_progress(paths, questions, answers)\n",
    "\n",
    "            processed_count += 1\n",
    "            if processed_count % 10 == 0:\n",
    "                print(f\"Processed {processed_count}/{total_images} images ({(processed_count/total_images)*100:.2f}%)\")\n",
    "        \n",
    "        if apis_exhausted:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nProcess interrupted by user. Saving progress...\")\n",
    "    save_progress(paths, questions, answers, is_final=True)\n",
    "    print(f\"\\nProcessing stopped at {processed_count}/{total_images} images\")\n",
    "    print(f\"Successfully generated {len(paths)} Q&A pairs\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "    save_progress(paths, questions, answers, is_final=True)\n",
    "    print(f\"\\nProcessing stopped at {processed_count}/{total_images} images\")\n",
    "    print(f\"Successfully generated {len(paths)} Q&A pairs\")\n",
    "\n",
    "# Save final progress if not already saved\n",
    "if len(paths) > 0:\n",
    "    save_progress(paths, questions, answers, is_final=True)\n",
    "    print(f\"\\nFinal processing complete: {processed_count}/{total_images} images processed\")\n",
    "    print(f\"Successfully generated {len(paths)} Q&A pairs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
